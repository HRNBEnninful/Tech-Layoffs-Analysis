{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d7a14",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.13.3' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy matplotlib seaborn scikit-learn\n",
    "%pip install kagglehub[pandas-datasets]\n",
    "%pip install tqm\n",
    "%pip install pmdarima\n",
    "%pip install keras\n",
    "%pip install tensorflow\n",
    "%pip install xgboost lightgbm catboost\n",
    "%pip install chardet\n",
    "%pip install pycountry\n",
    "%pip install pycountry_convert\n",
    "%pip install geopandas\n",
    "%pip install statsmodels prophet tensorflow scikit-learn plotly\n",
    "%pip install ipywidgets\n",
    "%pip install dash\n",
    "%pip install jupyter-dash\n",
    "%pip install lifelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757947f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "layoffs = pd.read_csv('layoffs.csv')\n",
    "\n",
    "layoffs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8570b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layoffs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb88d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "layoffs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layoffs.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d3d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 1. Exploratory Data Analysis \n",
    "# ------------------------------\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from dash import Dash, dcc, html\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Data Preparation\n",
    "# ------------------------------\n",
    "# Convert 'date' column to datetime\n",
    "layoffs['date'] = pd.to_datetime(layoffs['date'], errors='coerce')\n",
    "layoffs['year'] = layoffs['date'].dt.year\n",
    "\n",
    "# Impute numeric columns\n",
    "numeric_cols = ['total_laid_off', 'percentage_laid_off', 'funds_raised']  \n",
    "num_imputer = IterativeImputer(estimator=xgb.XGBRegressor(), max_iter=10, random_state=42)\n",
    "layoffs[numeric_cols] = num_imputer.fit_transform(layoffs[numeric_cols])\n",
    "\n",
    "# Impute categorical columns\n",
    "cat_cols = ['location', 'industry', 'stage'] \n",
    "encoders = {}\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    non_null = layoffs[col][layoffs[col].notnull()]\n",
    "    le.fit(non_null)\n",
    "    layoffs[col] = layoffs[col].map(lambda x: le.transform([x])[0] if pd.notnull(x) else np.nan)\n",
    "    encoders[col] = le\n",
    "\n",
    "cat_imputer = IterativeImputer(estimator=xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n",
    "                               max_iter=10, random_state=42)\n",
    "layoffs[cat_cols] = cat_imputer.fit_transform(layoffs[cat_cols])\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = encoders[col]\n",
    "    layoffs[col] = layoffs[col].round().astype(int)\n",
    "    layoffs[col] = layoffs[col].map(lambda x: le.inverse_transform([x])[0])\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Prepare monthly aggregated data\n",
    "# ------------------------------\n",
    "monthly_data = layoffs.set_index('date').resample('ME').agg({\n",
    "    'total_laid_off': 'sum',\n",
    "    'percentage_laid_off': 'mean'\n",
    "}).reset_index()\n",
    "monthly_data['rolling_avg'] = monthly_data['total_laid_off'].rolling(window=3).mean()\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Create plots\n",
    "# ------------------------------\n",
    "\n",
    "# Time-series figure\n",
    "ts_fig = go.Figure()\n",
    "ts_fig.add_trace(go.Scatter(\n",
    "    x=monthly_data['date'],\n",
    "    y=monthly_data['total_laid_off'],\n",
    "    mode='lines+markers',\n",
    "    name='Monthly Layoffs'\n",
    "))\n",
    "ts_fig.add_trace(go.Scatter(\n",
    "    x=monthly_data['date'],\n",
    "    y=monthly_data['rolling_avg'],\n",
    "    mode='lines+markers',\n",
    "    name='3-Month Rolling Avg',\n",
    "    line=dict(color='orange', width=3, dash='dash')\n",
    "))\n",
    "ts_fig.add_trace(go.Scatter(\n",
    "    x=monthly_data['date'],\n",
    "    y=monthly_data['percentage_laid_off'],\n",
    "    mode='lines+markers',\n",
    "    name='Average % Laid Off',\n",
    "    line=dict(color='green', width=3, dash='dot'),\n",
    "    yaxis='y2'\n",
    "))\n",
    "ts_fig.update_layout(\n",
    "    title='Monthly Layoffs, Rolling Average, and Average % Laid Off',\n",
    "    xaxis_title='Date',\n",
    "    yaxis=dict(title='Number of Employees Laid Off'),\n",
    "    yaxis2=dict(title='Average % Laid Off', overlaying='y', side='right'),\n",
    "    legend_title='Metrics',\n",
    "    height=500,\n",
    "    width=700\n",
    ")\n",
    "\n",
    "# Animated numeric distributions figures\n",
    "numeric_anim_figs = {}\n",
    "for col in numeric_cols:\n",
    "    anim_fig = px.histogram(\n",
    "        layoffs,\n",
    "        x=col,\n",
    "        animation_frame='year',\n",
    "        nbins=30,\n",
    "        range_x=[layoffs[col].min(), layoffs[col].max()],\n",
    "        title=f'Yearly Distribution of {col}',\n",
    "        labels={col: col},\n",
    "        opacity=0.75\n",
    "    )\n",
    "    anim_fig.update_layout(height=500, width=700, yaxis_title='Count')\n",
    "    numeric_anim_figs[col] = anim_fig\n",
    "\n",
    "# Categorical distributions with dropdown\n",
    "cat_fig = go.Figure()\n",
    "years = sorted(layoffs['year'].dropna().unique())\n",
    "for year in years:\n",
    "    filtered = layoffs[layoffs['year'] == year]\n",
    "    for col in cat_cols:\n",
    "        vc = filtered[col].value_counts().reset_index()\n",
    "        vc.columns = [col, 'count']\n",
    "        cat_fig.add_trace(go.Bar(\n",
    "            x=vc[col],\n",
    "            y=vc['count'],\n",
    "            name=col,\n",
    "            visible=(year == years[0])\n",
    "        ))\n",
    "\n",
    "# Prepare dropdown buttons\n",
    "buttons = []\n",
    "n_cols = len(cat_cols)\n",
    "for i, year in enumerate(years):\n",
    "    visible = [False] * len(years) * n_cols\n",
    "    for j in range(n_cols):\n",
    "        visible[i*n_cols + j] = True\n",
    "    buttons.append(dict(\n",
    "        label=str(year),\n",
    "        method='update',\n",
    "        args=[{'visible': visible},\n",
    "              {'title': f'Categorical Distributions for {year}'}]\n",
    "    ))\n",
    "\n",
    "cat_fig.update_layout(\n",
    "    updatemenus=[dict(\n",
    "        active=0,\n",
    "        buttons=buttons,\n",
    "        x=1.1,\n",
    "        y=1,\n",
    "        xanchor='right',\n",
    "        yanchor='top'\n",
    "    )],\n",
    "    title=f'Categorical Distributions for {years[0]}',\n",
    "    barmode='group',\n",
    "    height=500,\n",
    "    width=900\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Dash App\n",
    "# ------------------------------\n",
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Layoffs Data Dashboard\", style={'textAlign': 'center'}),\n",
    "    dcc.Tabs([\n",
    "        dcc.Tab(label='Time Series', children=[\n",
    "            dcc.Graph(figure=ts_fig)\n",
    "        ]),\n",
    "        dcc.Tab(label='Numeric Distributions', children=[\n",
    "            dcc.Dropdown(\n",
    "                id='numeric-dropdown',\n",
    "                options=[{'label': col, 'value': col} for col in numeric_cols],\n",
    "                value=numeric_cols[0],\n",
    "                clearable=False\n",
    "            ),\n",
    "            dcc.Graph(id='numeric-graph', figure=numeric_anim_figs[numeric_cols[0]])\n",
    "        ]),\n",
    "        dcc.Tab(label='Categorical Distributions', children=[\n",
    "            dcc.Graph(figure=cat_fig)\n",
    "        ])\n",
    "    ])\n",
    "])\n",
    "\n",
    "# Callback for numeric distribution dropdown\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "@app.callback(\n",
    "    Output('numeric-graph', 'figure'),\n",
    "    Input('numeric-dropdown', 'value')\n",
    ")\n",
    "def update_numeric_graph(selected_col):\n",
    "    return numeric_anim_figs[selected_col]\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Run app\n",
    "# ------------------------------\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861d90ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Exploratory Data Analysis\n",
    "# ------------------------------\n",
    "\n",
    "import plotly.express as px\n",
    "import pycountry\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure 'year' column exists\n",
    "layoffs['year'] = layoffs['date'].dt.year\n",
    "\n",
    "# Function to get ISO-3 country codes\n",
    "def get_country_code(name):\n",
    "    try:\n",
    "        country = pycountry.countries.lookup(name)\n",
    "        return country.alpha_3\n",
    "    except LookupError:\n",
    "        return None\n",
    "\n",
    "layoffs['country_code'] = layoffs['country'].apply(get_country_code)\n",
    "\n",
    "# Drop rows without valid country codes\n",
    "layoffs_clean = layoffs.dropna(subset=['country_code'])\n",
    "\n",
    "# Aggregate data by year and country\n",
    "agg_df = layoffs_clean.groupby(['year', 'country', 'country_code']).agg({\n",
    "    'total_laid_off': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Create choropleth with year dropdown\n",
    "years = sorted(agg_df['year'].unique())\n",
    "fig = px.choropleth(\n",
    "    agg_df[agg_df['year'] == years[0]],\n",
    "    locations='country_code',\n",
    "    color='total_laid_off',\n",
    "    hover_name='country',\n",
    "    color_continuous_scale=px.colors.sequential.Plasma,\n",
    "    title=f'Total Layoffs by Country - {years[0]}'\n",
    ")\n",
    "\n",
    "# Add dropdown buttons for each year\n",
    "buttons = []\n",
    "for year in years:\n",
    "    visible = agg_df['year'] == year\n",
    "    buttons.append(dict(\n",
    "        label=str(year),\n",
    "        method='update',\n",
    "        args=[{'z': [agg_df[visible]['total_laid_off']],\n",
    "               'locations': [agg_df[visible]['country_code']],\n",
    "               'hovertext': [agg_df[visible]['country']]},\n",
    "              {'title': f'Total Layoffs by Country - {year}'}]\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    updatemenus=[dict(\n",
    "        buttons=buttons,\n",
    "        x=1.1,\n",
    "        y=1,\n",
    "        xanchor='right',\n",
    "        yanchor='top'\n",
    "    )]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb16e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison between funding raised and layoffs over time\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from dash import Dash, dcc, html\n",
    "\n",
    "correlation = layoffs[['funds_raised', 'total_laid_off', 'percentage_laid_off']].corr().iloc[0,1]\n",
    "heatmap_fig = px.imshow(\n",
    "    layoffs[['funds_raised', 'total_laid_off', 'percentage_laid_off']].corr(),\n",
    "    text_auto=True,\n",
    "    color_continuous_scale='Viridis',\n",
    "    title='Correlation between Funds Raised and Total Laid Off'\n",
    ")\n",
    "heatmap_fig.show()\n",
    "\n",
    "print(f\"Correlation between funds raised and total laid off: {correlation:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52688b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Clustering Companies Based on Risk of Layoffs\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html, dash_table\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Data Preparation\n",
    "# -------------------------------\n",
    "layoffs_cluster = layoffs.copy()\n",
    "layoffs_cluster = layoffs_cluster.dropna(subset=[\n",
    "    'total_laid_off', 'percentage_laid_off', 'funds_raised', 'stage', 'industry', 'location'\n",
    "])\n",
    "layoffs_cluster = layoffs_cluster[['company', 'total_laid_off', 'percentage_laid_off',\n",
    "                                   'funds_raised', 'stage', 'industry', 'location']]\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "layoffs_encoded = pd.get_dummies(layoffs_cluster.drop('company', axis=1),\n",
    "                                 columns=['stage', 'industry', 'location'])\n",
    "\n",
    "# Standardize numeric features\n",
    "scaler = StandardScaler()\n",
    "layoffs_encoded[['total_laid_off', 'percentage_laid_off', 'funds_raised']] = scaler.fit_transform(\n",
    "    layoffs_encoded[['total_laid_off', 'percentage_laid_off', 'funds_raised']]\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. KMeans Clustering\n",
    "# -------------------------------\n",
    "optimal_k = 5\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "layoffs_encoded['cluster'] = kmeans.fit_predict(layoffs_encoded)\n",
    "layoffs_cluster['cluster'] = layoffs_encoded['cluster']\n",
    "\n",
    "# -------------------------------\n",
    "# 3. PCA for 2D Visualization\n",
    "# -------------------------------\n",
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(layoffs_encoded.drop('cluster', axis=1))\n",
    "\n",
    "pca_df = pd.DataFrame(data=components, columns=['PC1', 'PC2'])\n",
    "pca_df['cluster'] = layoffs_cluster['cluster'].astype(str)\n",
    "pca_df['company'] = layoffs_cluster['company']\n",
    "pca_df['industry'] = layoffs_cluster['industry']\n",
    "pca_df['stage'] = layoffs_cluster['stage']\n",
    "pca_df['location'] = layoffs_cluster['location']\n",
    "pca_df['total_laid_off'] = layoffs_cluster['total_laid_off']\n",
    "pca_df['percentage_laid_off'] = layoffs_cluster['percentage_laid_off']\n",
    "pca_df['funds_raised'] = layoffs_cluster['funds_raised']\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Build Dash App\n",
    "# -------------------------------\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "industry_options = [{'label': ind, 'value': ind} for ind in sorted(pca_df['industry'].unique())]\n",
    "stage_options = [{'label': st, 'value': st} for st in sorted(pca_df['stage'].unique())]\n",
    "location_options = [{'label': loc, 'value': loc} for loc in sorted(pca_df['location'].unique())]\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Tech Layoffs Cluster Dashboard\", style={'textAlign': 'center'}),\n",
    "    html.Div([\n",
    "        html.Label(\"Filter by Industry:\"),\n",
    "        dcc.Dropdown(id='industry-dropdown', options=industry_options, multi=True, placeholder=\"Select industry\"),\n",
    "        html.Label(\"Filter by Stage:\"),\n",
    "        dcc.Dropdown(id='stage-dropdown', options=stage_options, multi=True, placeholder=\"Select company stage\"),\n",
    "        html.Label(\"Filter by Location:\"),\n",
    "        dcc.Dropdown(id='location-dropdown', options=location_options, multi=True, placeholder=\"Select location\"),\n",
    "    ], style={'width': '25%', 'display': 'inline-block', 'verticalAlign': 'top', 'padding': '20px'}),\n",
    "    html.Div([\n",
    "        dcc.Graph(id='cluster-graph'),\n",
    "        html.H3(\"Cluster Summary\"),\n",
    "        html.Div(id='cluster-text-summary', style={'marginBottom': '10px', 'fontStyle': 'italic'}),\n",
    "        dash_table.DataTable(\n",
    "            id='cluster-summary',\n",
    "            columns=[\n",
    "                {\"name\": \"Cluster\", \"id\": \"cluster\"},\n",
    "                {\"name\": \"Avg Total Laid Off\", \"id\": \"avg_total_laid_off\"},\n",
    "                {\"name\": \"Avg % Laid Off\", \"id\": \"avg_percentage_laid_off\"},\n",
    "                {\"name\": \"Avg Funds Raised\", \"id\": \"avg_funds_raised\"}\n",
    "            ],\n",
    "            style_table={'overflowX': 'auto'},\n",
    "            style_cell={'textAlign': 'center'},\n",
    "            style_header={'fontWeight': 'bold'},\n",
    "        ),\n",
    "        html.Br(),\n",
    "        html.Button(\"Download Cluster Summary\", id=\"btn-download\", n_clicks=0),\n",
    "        dcc.Download(id=\"download-cluster-summary\")\n",
    "    ], style={'width': '70%', 'display': 'inline-block'})\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Callbacks\n",
    "# -------------------------------\n",
    "@app.callback(\n",
    "    [Output('cluster-graph', 'figure'),\n",
    "     Output('cluster-summary', 'data'),\n",
    "     Output('cluster-text-summary', 'children'),\n",
    "     Output('download-cluster-summary', 'data')],\n",
    "    [Input('industry-dropdown', 'value'),\n",
    "     Input('stage-dropdown', 'value'),\n",
    "     Input('location-dropdown', 'value'),\n",
    "     Input('btn-download', 'n_clicks')],\n",
    "    prevent_initial_call=False\n",
    ")\n",
    "def update_graph(selected_industries, selected_stages, selected_locations, n_clicks):\n",
    "    filtered_df = pca_df.copy()\n",
    "    if selected_industries:\n",
    "        filtered_df = filtered_df[filtered_df['industry'].isin(selected_industries)]\n",
    "    if selected_stages:\n",
    "        filtered_df = filtered_df[filtered_df['stage'].isin(selected_stages)]\n",
    "    if selected_locations:\n",
    "        filtered_df = filtered_df[filtered_df['location'].isin(selected_locations)]\n",
    "\n",
    "    # Scatter plot\n",
    "    fig = px.scatter(\n",
    "        filtered_df,\n",
    "        x='PC1', y='PC2',\n",
    "        color='cluster',\n",
    "        hover_data=['company', 'industry', 'stage', 'location'],\n",
    "        title='PCA Visualization of Layoffs Clusters'\n",
    "    )\n",
    "    fig.update_layout(height=500, width=700)\n",
    "\n",
    "    # Cluster summary table\n",
    "    summary = (\n",
    "        filtered_df.groupby('cluster')\n",
    "        .agg(\n",
    "            avg_total_laid_off=('total_laid_off', 'mean'),\n",
    "            avg_percentage_laid_off=('percentage_laid_off', 'mean'),\n",
    "            avg_funds_raised=('funds_raised', 'mean')\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    summary['avg_total_laid_off'] = summary['avg_total_laid_off'].round(2)\n",
    "    summary['avg_percentage_laid_off'] = summary['avg_percentage_laid_off'].round(2)\n",
    "    summary['avg_funds_raised'] = summary['avg_funds_raised'].round(2)\n",
    "\n",
    "    # Generate textual summary per cluster\n",
    "    text_summaries = []\n",
    "    for _, row in summary.iterrows():\n",
    "        cluster_text = (f\"Cluster {row['cluster']}: On average, companies laid off {row['avg_total_laid_off']} employees \"\n",
    "                        f\"({row['avg_percentage_laid_off']}% of workforce) with average funds raised of ${row['avg_funds_raised']}M.\")\n",
    "        text_summaries.append(cluster_text)\n",
    "    text_summary_str = html.Ul([html.Li(txt) for txt in text_summaries])\n",
    "\n",
    "    # Prepare download data\n",
    "    download_data = None\n",
    "    if n_clicks > 0:\n",
    "        download_data = dcc.send_data_frame(summary.to_csv, \"cluster_summary.csv\", index=False)\n",
    "\n",
    "    return fig, summary.to_dict('records'), text_summary_str, download_data\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Run app\n",
    "# -------------------------------\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e00d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Industry-Normalized Anomaly Detection & Clustering of Layoffs\n",
    "# ============================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import dash\n",
    "from dash import dcc, html, dash_table\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Data Preparation\n",
    "# -------------------------------\n",
    "layoffs_anomaly = layoffs.copy()\n",
    "layoffs_anomaly = layoffs_anomaly.dropna(subset=[\n",
    "    'company','total_laid_off','percentage_laid_off','funds_raised','industry'\n",
    "])\n",
    "layoffs_anomaly = layoffs_anomaly[['company','total_laid_off','percentage_laid_off','funds_raised','industry']]\n",
    "\n",
    "# Standardize within industry\n",
    "def industry_standardize(df):\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[['total_laid_off','percentage_laid_off','funds_raised']] = \\\n",
    "        df_scaled.groupby('industry')[['total_laid_off','percentage_laid_off','funds_raised']].transform(\n",
    "            lambda x: ((x - x.mean()) / x.std(ddof=0)).fillna(0)\n",
    "        )\n",
    "    return df_scaled\n",
    "\n",
    "layoffs_scaled = industry_standardize(layoffs_anomaly)\n",
    "\n",
    "# One-hot encode industry\n",
    "layoffs_encoded = pd.get_dummies(layoffs_scaled.drop('company', axis=1), columns=['industry'])\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Anomaly Detection\n",
    "# -------------------------------\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "layoffs_encoded['anomaly'] = iso_forest.fit_predict(layoffs_encoded)\n",
    "layoffs_anomaly['anomaly'] = layoffs_encoded['anomaly']\n",
    "layoffs_anomaly['anomaly_label'] = layoffs_anomaly['anomaly'].map({1:'Normal', -1:'Anomaly'})\n",
    "\n",
    "# -------------------------------\n",
    "# 3. PCA for 2D Visualization\n",
    "# -------------------------------\n",
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(layoffs_encoded.drop('anomaly', axis=1))\n",
    "pca_df = pd.DataFrame(components, columns=['PC1','PC2'])\n",
    "pca_df = pd.concat([pca_df, layoffs_anomaly[['company','total_laid_off','percentage_laid_off','funds_raised','industry','anomaly_label']]], axis=1)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Cluster anomalies\n",
    "# -------------------------------\n",
    "def cluster_anomalies(df):\n",
    "    anomaly_data = df[df['anomaly_label']=='Anomaly'].copy()\n",
    "    if anomaly_data.empty:\n",
    "        df['cluster'] = np.nan\n",
    "        return df\n",
    "    n_clusters = min(5, len(anomaly_data))\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    anomaly_data['cluster'] = kmeans.fit_predict(anomaly_data[['PC1','PC2']])\n",
    "    df = df.merge(anomaly_data[['company','cluster']], on='company', how='left')\n",
    "    return df\n",
    "\n",
    "pca_df = cluster_anomalies(pca_df)\n",
    "pca_df['cluster_plot'] = pca_df['cluster'].fillna(-1).astype(int)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Dash App\n",
    "# -------------------------------\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Layoff Anomaly Detection by Industry\"),\n",
    "    \n",
    "    html.Label(\"Select Industry:\"),\n",
    "    dcc.Dropdown(\n",
    "        id='industry-dropdown',\n",
    "        options=[{'label': i, 'value': i} for i in sorted(pca_df['industry'].unique())] + [{'label':'All','value':'All'}],\n",
    "        value='All'\n",
    "    ),\n",
    "    \n",
    "    dcc.Graph(id='pca-graph'),\n",
    "    \n",
    "    html.H3(\"Summary of Groups\"),\n",
    "    html.Div(id='group-summary-text'),\n",
    "    \n",
    "    dash_table.DataTable(\n",
    "        id='group-summary-table',\n",
    "        columns=[\n",
    "            {\"name\": \"Company\", \"id\": \"company\"},\n",
    "            {\"name\": \"Industry\", \"id\": \"industry\"},\n",
    "            {\"name\": \"Total Laid Off\", \"id\": \"total_laid_off\"},\n",
    "            {\"name\": \"% Laid Off\", \"id\": \"percentage_laid_off\"},\n",
    "            {\"name\": \"Funds Raised\", \"id\": \"funds_raised\"},\n",
    "            {\"name\": \"Anomaly Label\", \"id\": \"anomaly_label\"},\n",
    "            {\"name\": \"Cluster\", \"id\": \"cluster\"}\n",
    "        ],\n",
    "        page_size=10,\n",
    "        style_table={'overflowX': 'auto'},\n",
    "        style_cell={'textAlign': 'center'},\n",
    "        style_header={'fontWeight': 'bold'}\n",
    "    ),\n",
    "    \n",
    "    html.Br(),\n",
    "    html.Button(\"Download Summary CSV\", id=\"btn-download\", n_clicks=0),\n",
    "    dcc.Download(id=\"download-summary\")\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Callbacks\n",
    "# -------------------------------\n",
    "@app.callback(\n",
    "    [Output('pca-graph', 'figure'),\n",
    "     Output('group-summary-text', 'children'),\n",
    "     Output('group-summary-table', 'data'),\n",
    "     Output('download-summary', 'data')],\n",
    "    [Input('industry-dropdown','value'),\n",
    "     Input('btn-download','n_clicks')]\n",
    ")\n",
    "def update_dashboard(selected_industry, n_clicks):\n",
    "    df_plot = pca_df.copy()\n",
    "    if selected_industry != 'All':\n",
    "        df_plot = df_plot[df_plot['industry'] == selected_industry]\n",
    "    \n",
    "    # PCA Scatter plot with hover info\n",
    "    df_plot['marker_size'] = df_plot['anomaly_label'].map({'Normal':10, 'Anomaly':15})\n",
    "    fig = px.scatter(\n",
    "        df_plot,\n",
    "        x='PC1', y='PC2',\n",
    "        color='anomaly_label',\n",
    "        symbol='cluster_plot',\n",
    "        size='marker_size',\n",
    "        opacity=0.7,\n",
    "        hover_data={\n",
    "            'company': True,\n",
    "            'industry': True,\n",
    "            'total_laid_off': True,\n",
    "            'percentage_laid_off': True,\n",
    "            'funds_raised': True,\n",
    "            'cluster_plot': True,\n",
    "            'PC1': False,\n",
    "            'PC2': False,\n",
    "            'marker_size': False\n",
    "        },\n",
    "        title=f\"PCA of Layoffs: {selected_industry}\"\n",
    "    )\n",
    "    fig.update_traces(marker=dict(line=dict(width=1, color='DarkSlateGrey')))\n",
    "\n",
    "    # -------------------------------\n",
    "    # Textual Summary of Normal and Anomaly Groups (with company names)\n",
    "    # -------------------------------\n",
    "    summary_text = []\n",
    "    \n",
    "    # Normal group\n",
    "    normal_df = df_plot[df_plot['anomaly_label']=='Normal']\n",
    "    if not normal_df.empty:\n",
    "        summary_text.append(\n",
    "            html.Li(f\"Normal Group: {len(normal_df)} companies, \"\n",
    "                    f\"Avg layoffs: {normal_df['total_laid_off'].mean():.1f}, \"\n",
    "                    f\"Avg % laid off: {normal_df['percentage_laid_off'].mean():.1f}%, \"\n",
    "                    f\"Avg funds raised: {normal_df['funds_raised'].mean():.2f}M. \"\n",
    "                    f\"Companies: {', '.join(normal_df['company'].tolist())}\")\n",
    "        )\n",
    "\n",
    "    # Anomaly clusters\n",
    "    anomaly_df = df_plot[df_plot['anomaly_label']=='Anomaly']\n",
    "    if not anomaly_df.empty:\n",
    "        for cl in sorted(anomaly_df['cluster_plot'].unique()):\n",
    "            cl_df = anomaly_df[anomaly_df['cluster_plot']==cl]\n",
    "            company_list = \", \".join(cl_df['company'].tolist())\n",
    "            summary_text.append(\n",
    "                html.Li(f\"Anomaly Cluster {cl}: {len(cl_df)} companies, \"\n",
    "                        f\"Avg layoffs: {cl_df['total_laid_off'].mean():.1f}, \"\n",
    "                        f\"Avg % laid off: {cl_df['percentage_laid_off'].mean():.1f}%, \"\n",
    "                        f\"Avg funds raised: {cl_df['funds_raised'].mean():.2f}M. \"\n",
    "                        f\"Companies: {company_list}\")\n",
    "            )\n",
    "    \n",
    "    summary_text_component = html.Ul(summary_text)\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Table\n",
    "    # -------------------------------\n",
    "    table_data = df_plot[['company','industry','total_laid_off','percentage_laid_off','funds_raised','anomaly_label','cluster_plot']].rename(columns={'cluster_plot':'cluster'}).to_dict('records')\n",
    "    \n",
    "    # -------------------------------\n",
    "    # CSV Download\n",
    "    # -------------------------------\n",
    "    download_data = None\n",
    "    if n_clicks > 0:\n",
    "        download_data = dcc.send_data_frame(pd.DataFrame(table_data).to_csv, \"layoff_summary.csv\", index=False)\n",
    "    \n",
    "    return fig, summary_text_component, table_data, download_data\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Run App\n",
    "# -------------------------------\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c519ff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Layoffs Survival Analysis: Kaplan-Meier & Cox Proportional Hazards\n",
    "# ============================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "import plotly.graph_objects as go\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Data Preparation\n",
    "# -------------------------------\n",
    "layoffs_survival = layoffs.copy()\n",
    "\n",
    "# Drop rows with missing critical info\n",
    "layoffs_survival = layoffs_survival.dropna(subset=['date', 'total_laid_off', 'funds_raised'])\n",
    "\n",
    "# Event: whether a layoff occurred\n",
    "layoffs_survival['event'] = (layoffs_survival['total_laid_off'] > 0).astype(int)\n",
    "\n",
    "# Time to event (days since first recorded layoff)\n",
    "layoffs_survival['time_to_event'] = (layoffs_survival['date'] - layoffs_survival['date'].min()).dt.days\n",
    "layoffs_survival = layoffs_survival[layoffs_survival['time_to_event'] >= 0]\n",
    "\n",
    "# Log-transform funding\n",
    "layoffs_survival['funds_raised'] = np.log1p(layoffs_survival['funds_raised'])\n",
    "\n",
    "# Indicator for post-2022 crash\n",
    "layoffs_survival['post_2022_crash'] = (layoffs_survival['date'] >= pd.to_datetime('2022-01-01')).astype(int)\n",
    "\n",
    "# Categorize funding\n",
    "funds_quantiles = layoffs_survival['funds_raised'].quantile([0.33, 0.66])\n",
    "layoffs_survival['funds_category'] = pd.cut(\n",
    "    layoffs_survival['funds_raised'],\n",
    "    bins=[-np.inf, funds_quantiles[0.33], funds_quantiles[0.66], np.inf],\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Dash App Layout\n",
    "# -------------------------------\n",
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Layoffs Survival Analysis\", style={'textAlign': 'center'}),\n",
    "\n",
    "    html.Div([\n",
    "        html.Label(\"Filter Type:\"),\n",
    "        dcc.Dropdown(\n",
    "            id=\"filter-type\",\n",
    "            options=[\n",
    "                {\"label\": \"All Data\", \"value\": \"all\"},\n",
    "                {\"label\": \"By Country\", \"value\": \"country\"},\n",
    "                {\"label\": \"By Stage\", \"value\": \"stage\"}\n",
    "            ],\n",
    "            value=\"all\",\n",
    "            clearable=False\n",
    "        )\n",
    "    ], style={\"margin\": \"20px\"}),\n",
    "\n",
    "    html.Div([\n",
    "        html.Label(\"Select Value (if applicable):\"),\n",
    "        dcc.Dropdown(id=\"filter-value\", clearable=True)\n",
    "    ], style={\"margin\": \"20px\"}),\n",
    "\n",
    "    html.Div([\n",
    "        html.H2(\"Kaplan-Meier Survival Curve\"),\n",
    "        dcc.Graph(id=\"km-plot\"),\n",
    "        html.Div(id=\"km-summary\", style={\"margin\": \"20px\", \"fontStyle\": \"italic\"})\n",
    "    ]),\n",
    "\n",
    "    html.Div([\n",
    "        html.H2(\"Cox Proportional Hazards Model\"),\n",
    "        dcc.Graph(id=\"cox-plot\"),\n",
    "        html.Div(id=\"cox-summary\", style={\"margin\": \"20px\", \"fontStyle\": \"italic\"})\n",
    "    ])\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Callbacks\n",
    "# -------------------------------\n",
    "\n",
    "# Update second dropdown options dynamically\n",
    "@app.callback(\n",
    "    Output(\"filter-value\", \"options\"),\n",
    "    Input(\"filter-type\", \"value\")\n",
    ")\n",
    "def update_filter_values(filter_choice):\n",
    "    if filter_choice == \"country\":\n",
    "        return [{\"label\": c, \"value\": c} for c in sorted(layoffs_survival['country'].dropna().unique())]\n",
    "    elif filter_choice == \"stage\":\n",
    "        return [{\"label\": s, \"value\": s} for s in sorted(layoffs_survival['stage'].dropna().unique())]\n",
    "    return []\n",
    "\n",
    "# Update plots + summaries\n",
    "@app.callback(\n",
    "    [Output(\"km-plot\", \"figure\"),\n",
    "     Output(\"km-summary\", \"children\"),\n",
    "     Output(\"cox-plot\", \"figure\"),\n",
    "     Output(\"cox-summary\", \"children\")],\n",
    "    [Input(\"filter-type\", \"value\"),\n",
    "     Input(\"filter-value\", \"value\")]\n",
    ")\n",
    "def update_plots(filter_choice, filter_value):\n",
    "    data = layoffs_survival.copy()\n",
    "\n",
    "    # Apply filter if applicable\n",
    "    if filter_choice == \"country\" and filter_value:\n",
    "        data = data[data['country'] == filter_value]\n",
    "    elif filter_choice == \"stage\" and filter_value:\n",
    "        data = data[data['stage'] == filter_value]\n",
    "\n",
    "    # --------------------\n",
    "    # Kaplan-Meier\n",
    "    # --------------------\n",
    "    kmf = KaplanMeierFitter()\n",
    "    fig_km = go.Figure()\n",
    "    km_texts = []\n",
    "\n",
    "    medians = {}\n",
    "    for fund_level in data['funds_category'].dropna().unique():\n",
    "        subset = data[data['funds_category'] == fund_level]\n",
    "        if len(subset) > 0:\n",
    "            kmf.fit(subset['time_to_event'], subset['event'], label=f\"Funds {fund_level}\")\n",
    "            temp_df = kmf.survival_function_.reset_index()\n",
    "            fig_km.add_trace(go.Scatter(\n",
    "                x=temp_df['timeline'],\n",
    "                y=temp_df[kmf._label],\n",
    "                mode='lines',\n",
    "                name=f\"Funds {fund_level}\"\n",
    "            ))\n",
    "            # Median survival\n",
    "            med_surv = kmf.median_survival_time_\n",
    "            medians[fund_level] = med_surv\n",
    "            km_texts.append(f\"Funding {fund_level}: Median survival ≈ {med_surv:.0f} days\")\n",
    "\n",
    "    fig_km.update_layout(\n",
    "        title=\"Kaplan-Meier Survival Curve\",\n",
    "        xaxis_title=\"Days Since First Recorded Layoff\",\n",
    "        yaxis_title=\"Survival Probability\",\n",
    "        height=500, width=700\n",
    "    )\n",
    "\n",
    "    # Sort medians to show ranking\n",
    "    if medians:\n",
    "        ranking = sorted(medians.items(), key=lambda x: x[1], reverse=True)\n",
    "        ranking_str = \" → \".join([f\"{k} ({v:.0f}d)\" for k, v in ranking])\n",
    "        km_texts.append(f\"Ranking by median survival: {ranking_str}\")\n",
    "    km_summary_text = html.Ul([html.Li(txt) for txt in km_texts]) if km_texts else \"Not enough data for KM summary.\"\n",
    "\n",
    "    # --------------------\n",
    "    # Cox Proportional Hazards\n",
    "    # --------------------\n",
    "    cox_vars = ['time_to_event', 'event', 'funds_raised', 'post_2022_crash', 'funds_category']\n",
    "    if filter_choice in [\"country\", \"stage\"]:\n",
    "        cox_vars.append(filter_choice)\n",
    "\n",
    "    df_cox = data[cox_vars].copy()\n",
    "    df_cox = pd.get_dummies(df_cox, drop_first=True)\n",
    "    df_cox = df_cox.dropna()\n",
    "\n",
    "    fig_cph = go.Figure()\n",
    "    cox_summary_text = \"Not enough data for Cox PH model.\"\n",
    "\n",
    "    if len(df_cox) > 10:  # Ensure enough samples\n",
    "        cph = CoxPHFitter(penalizer=0.1)\n",
    "        cph.fit(df_cox, duration_col='time_to_event', event_col='event')\n",
    "\n",
    "        cph_summary = cph.summary.reset_index()\n",
    "        cph_summary['exp(coef)'] = np.exp(cph_summary['coef'])\n",
    "        cph_summary['exp(coef) lower 95%'] = np.exp(cph_summary['coef lower 95%'])\n",
    "        cph_summary['exp(coef) upper 95%'] = np.exp(cph_summary['coef upper 95%'])\n",
    "\n",
    "        # Plot hazard ratios\n",
    "        fig_cph.add_trace(go.Bar(\n",
    "            x=cph_summary['covariate'],\n",
    "            y=cph_summary['exp(coef)'],\n",
    "            error_y=dict(\n",
    "                type='data',\n",
    "                symmetric=False,\n",
    "                array=cph_summary['exp(coef) upper 95%'] - cph_summary['exp(coef)'],\n",
    "                arrayminus=cph_summary['exp(coef)'] - cph_summary['exp(coef) lower 95%']\n",
    "            ),\n",
    "            name='Hazard Ratios'\n",
    "        ))\n",
    "\n",
    "        fig_cph.update_layout(\n",
    "            title=\"Cox Proportional Hazards Model Results\",\n",
    "            xaxis_title=\"Covariates\",\n",
    "            yaxis_title=\"Hazard Ratio\",\n",
    "            height=500, width=700\n",
    "        )\n",
    "\n",
    "        # Build textual interpretation\n",
    "        texts = []\n",
    "        for _, row in cph_summary.iterrows():\n",
    "            cov = row['covariate']\n",
    "            hr = row['exp(coef)']\n",
    "            pval = row['p']\n",
    "            if hr > 1:\n",
    "                effect = \"increases hazard (layoff risk)\"\n",
    "            else:\n",
    "                effect = \"decreases hazard (layoff risk)\"\n",
    "            sig = \" ⭐\" if pval < 0.05 else \"\"\n",
    "            texts.append(f\"{cov}: HR={hr:.2f}, p={pval:.3f}{sig} → {effect}\")\n",
    "        cox_summary_text = html.Ul([html.Li(t) for t in texts])\n",
    "\n",
    "    return fig_km, km_summary_text, fig_cph, cox_summary_text\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Run App\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
